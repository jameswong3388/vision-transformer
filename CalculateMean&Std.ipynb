{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3847fc78-aba4-4db8-9e23-b5098bbe590d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T05:48:29.975873Z",
     "start_time": "2023-11-10T05:48:28.503048Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "####### PACKAGES\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "from pandas.core.common import flatten\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "####### PARAMS\n",
    "\n",
    "device      = torch.device('cpu') \n",
    "num_workers = 4\n",
    "image_size  = 32 \n",
    "batch_size  = 32\n",
    "data_path   = 'datas/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ecd3a92-d429-4f25-8376-f696cc5c7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WayangKulit(Dataset):\n",
    "    def __init__(self, dataset_path, transform):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.dataset = load_dataset(path=self.dataset_path, name='wayang_kulit')\n",
    "\n",
    "        self.train_image_paths = []\n",
    "        self.classes = []\n",
    "\n",
    "        for data_path in glob.glob(self.dataset_path + '/*'):\n",
    "            self.classes.append(data_path.split('/')[-1])\n",
    "            self.train_image_paths.append(glob.glob(data_path + '/*'))\n",
    "\n",
    "        self.train_image_paths = list(flatten(self.train_image_paths))\n",
    "        random.shuffle(self.train_image_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset['train'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.train_image_paths[idx]\n",
    "\n",
    "        image = cv2.imread(image_filepath)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image = image)['image']\n",
    "\n",
    "        idx_to_class = {i: j for i, j in enumerate(self.classes)}\n",
    "        class_to_idx = {value: key for key, value in idx_to_class.items()}\n",
    "\n",
    "        label = image_filepath.split('/')[-2]\n",
    "        label = class_to_idx[label]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "974afd24-3204-4277-a0ad-0042bd56a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = A.Compose([A.Resize(height = image_size, \n",
    "                           width  = image_size),\n",
    "                  A.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1)),\n",
    "                  ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09e711e7-7f79-4761-a872-3c6c594c393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7f4d8d81d446a991ba247af1af2ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### EXAMINE SAMPLE BATCH\n",
    "\n",
    "# dataset\n",
    "image_dataset = WayangKulit(data_path, transform=augs)\n",
    "\n",
    "# data loader\n",
    "image_loader = DataLoader(image_dataset, \n",
    "                          batch_size  = 32, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 0,\n",
    "                          pin_memory  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61605f36-db4c-4ddf-8bb9-c5e957af85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/43 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# loop through images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs \u001b[38;5;129;01min\u001b[39;00m tqdm(image_loader):\n\u001b[0;32m----> 9\u001b[0m     psum    \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m(axis        \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     10\u001b[0m     psum_sq \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (inputs \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "####### COMPUTE MEAN / STD\n",
    "\n",
    "# placeholders\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs in tqdm(image_loader):\n",
    "    psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
